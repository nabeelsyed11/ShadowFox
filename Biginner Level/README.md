# ğŸ–¼ï¸ CIFAR-10 Image Classification using CNN  

## ğŸ“Œ Project Overview  
This project demonstrates **image classification** using a **Convolutional Neural Network (CNN)** built with **TensorFlow/Keras**.  
The model is trained on the **CIFAR-10 dataset**, which contains **60,000 color images** (32Ã—32 pixels) in **10 different classes**.  

It is a **beginner-friendly deep learning project** that helps understand how CNNs work for computer vision tasks.  

---

## ğŸ¯ Objectives  
- Learn how to preprocess and normalize image datasets.  
- Build a custom CNN model from scratch.  
- Train the model using supervised learning.  
- Evaluate accuracy on unseen test data.  
- Provide a foundation for more advanced image classification tasks.  

---

## ğŸ—‚ï¸ Dataset â€“ CIFAR-10  
- **Training set:** 50,000 images  
- **Test set:** 10,000 images  
- **Image size:** 32Ã—32 pixels (RGB)  
- **Classes (10):**  
  1. Airplane âœˆï¸  
  2. Automobile ğŸš—  
  3. Bird ğŸ¦  
  4. Cat ğŸ±  
  5. Deer ğŸ¦Œ  
  6. Dog ğŸ¶  
  7. Frog ğŸ¸  
  8. Horse ğŸ  
  9. Ship ğŸš¢  
  10. Truck ğŸšš  

---

## ğŸ§  Model Architecture  
The CNN model is built using the **Keras Functional API**:  

1. **Input Layer:** Shape (32, 32, 3)  
2. **Conv Block 1:**  
   - Conv2D (32 filters, 3Ã—3, ReLU) â†’ BatchNorm  
   - Conv2D (32 filters, 3Ã—3, ReLU) â†’ BatchNorm  
   - MaxPooling2D (2Ã—2)  
   - Dropout (0.2)  

3. **Conv Block 2:**  
   - Conv2D (64 filters, 3Ã—3, ReLU) â†’ BatchNorm  
   - Conv2D (64 filters, 3Ã—3, ReLU) â†’ BatchNorm  
   - MaxPooling2D (2Ã—2)  
   - Dropout (0.2)  

4. **Fully Connected Layers:**  
   - Flatten  
   - Dense (1024 neurons, ReLU) â†’ Dropout (0.2)  
   - Dense (10 neurons, Softmax) â†’ Output  

---

## âš™ï¸ Techniques Used  
- **Supervised Learning**  
- **Convolutional Neural Networks (CNNs)**  
- **Batch Normalization** (stabilizes learning)  
- **Dropout** (reduces overfitting)  
- **MaxPooling** (downsamples feature maps)  
- **Softmax Activation** (multi-class classification)  
- **Adam Optimizer** (adaptive learning rate)  
- **Sparse Categorical Crossentropy Loss**  

---

## ğŸ“Š Training  
- **Epochs:** 50  
- **Optimizer:** Adam  
- **Loss Function:** Sparse Categorical Crossentropy  
- **Metric:** Accuracy  

---

## ğŸ“ˆ Results  
- The model achieves around **70â€“80% test accuracy** (depending on training).  
- Accuracy can be improved with:  
  - More training epochs  
  - Data augmentation  
  - Pre-trained models (VGG, ResNet, etc.)  

---

## ğŸš€ How to Run  
1. Clone this repository:  
   ```bash
   git clone https://github.com/your-username/cifar10-cnn.git
   cd cifar10-cnn
   ```
2. Install dependencies:  
   ```bash
   pip install tensorflow numpy matplotlib
   ```
3. Run the notebook:  
   ```bash
   jupyter notebook Biginner_level.ipynb
   ```

---

## ğŸ“Œ Future Improvements  
- Use **Data Augmentation** to make the model more robust.  
- Try **transfer learning** with pretrained models like **ResNet, VGG16, MobileNet**.  
- Deploy the model using **Flask/Streamlit** for a web demo.  

---

## ğŸ† Skills Gained  
- TensorFlow/Keras  
- CNNs for Computer Vision  
- Image Preprocessing  
- Model Training & Evaluation  
- Overfitting Prevention (Dropout, BatchNorm)  

---

## ğŸ“¬ Author  
ğŸ‘¤ **Syed Nabeel Ahmed**  
- [GitHub](https://github.com/nabeelsyed11)  
- [LinkedIn](https://www.linkedin.com/in/syed-ahmed-64052a32a/)  

---

âœ¨ *This project is a beginner-friendly introduction to Deep Learning for Computer Vision using CNNs.*  
