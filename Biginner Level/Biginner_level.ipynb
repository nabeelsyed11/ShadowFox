{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zkie1EpXfNST"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Impoprting Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
        "\n",
        "# Data Preperation & Load Model\n",
        "# Using THe Preloaded datasets from cifar10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev1cR9vm418p",
        "outputId": "3eaaec8f-c683-48aa-cf22-f062e9faf45f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "K = len(set(y_train))  # number of classes\n",
        "i = Input(shape=x_train[0].shape)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='same')(i)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2,2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(K, activation='softmax')(x)\n",
        "\n",
        "model = Model(i, x)\n",
        "# Model building\n"
      ],
      "metadata": {
        "id": "uI7OHf_e47lM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50)\n",
        "\n",
        "# Compile and Train the model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0tvWDIl4-F-",
        "outputId": "c69c5912-5577-4f42-996d-7b7c133899cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 229ms/step - accuracy: 0.4555 - loss: 1.7987 - val_accuracy: 0.6762 - val_loss: 0.9375\n",
            "Epoch 2/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 229ms/step - accuracy: 0.6803 - loss: 0.9185 - val_accuracy: 0.6969 - val_loss: 0.8882\n",
            "Epoch 3/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 228ms/step - accuracy: 0.7417 - loss: 0.7352 - val_accuracy: 0.7261 - val_loss: 0.8122\n",
            "Epoch 4/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 229ms/step - accuracy: 0.7836 - loss: 0.6252 - val_accuracy: 0.7631 - val_loss: 0.6985\n",
            "Epoch 5/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 229ms/step - accuracy: 0.8237 - loss: 0.5103 - val_accuracy: 0.7622 - val_loss: 0.7722\n",
            "Epoch 6/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 224ms/step - accuracy: 0.8515 - loss: 0.4276 - val_accuracy: 0.7631 - val_loss: 0.7211\n",
            "Epoch 7/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 224ms/step - accuracy: 0.8810 - loss: 0.3404 - val_accuracy: 0.7831 - val_loss: 0.7156\n",
            "Epoch 8/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 228ms/step - accuracy: 0.9006 - loss: 0.2830 - val_accuracy: 0.7895 - val_loss: 0.6948\n",
            "Epoch 9/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 228ms/step - accuracy: 0.9176 - loss: 0.2390 - val_accuracy: 0.7916 - val_loss: 0.7852\n",
            "Epoch 10/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 224ms/step - accuracy: 0.9278 - loss: 0.2130 - val_accuracy: 0.7971 - val_loss: 0.7618\n",
            "Epoch 11/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 224ms/step - accuracy: 0.9376 - loss: 0.1847 - val_accuracy: 0.7937 - val_loss: 0.7529\n",
            "Epoch 12/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 224ms/step - accuracy: 0.9445 - loss: 0.1654 - val_accuracy: 0.7967 - val_loss: 0.8409\n",
            "Epoch 13/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 228ms/step - accuracy: 0.9502 - loss: 0.1444 - val_accuracy: 0.7982 - val_loss: 0.7867\n",
            "Epoch 14/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 230ms/step - accuracy: 0.9530 - loss: 0.1418 - val_accuracy: 0.7845 - val_loss: 0.9034\n",
            "Epoch 15/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 228ms/step - accuracy: 0.9593 - loss: 0.1258 - val_accuracy: 0.7947 - val_loss: 0.9069\n",
            "Epoch 16/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 228ms/step - accuracy: 0.9594 - loss: 0.1225 - val_accuracy: 0.7887 - val_loss: 0.9900\n",
            "Epoch 17/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 228ms/step - accuracy: 0.9604 - loss: 0.1162 - val_accuracy: 0.7917 - val_loss: 0.9034\n",
            "Epoch 18/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 224ms/step - accuracy: 0.9639 - loss: 0.1073 - val_accuracy: 0.7997 - val_loss: 0.8952\n",
            "Epoch 19/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 228ms/step - accuracy: 0.9665 - loss: 0.0979 - val_accuracy: 0.8055 - val_loss: 0.9350\n",
            "Epoch 20/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m377s\u001b[0m 225ms/step - accuracy: 0.9688 - loss: 0.0950 - val_accuracy: 0.7934 - val_loss: 0.9731\n",
            "Epoch 21/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 226ms/step - accuracy: 0.9689 - loss: 0.0952 - val_accuracy: 0.8079 - val_loss: 0.8809\n",
            "Epoch 22/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 224ms/step - accuracy: 0.9713 - loss: 0.0881 - val_accuracy: 0.7910 - val_loss: 1.0357\n",
            "Epoch 23/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m351s\u001b[0m 225ms/step - accuracy: 0.9732 - loss: 0.0803 - val_accuracy: 0.8013 - val_loss: 0.8862\n",
            "Epoch 24/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 228ms/step - accuracy: 0.9759 - loss: 0.0729 - val_accuracy: 0.8038 - val_loss: 0.8950\n",
            "Epoch 25/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 224ms/step - accuracy: 0.9754 - loss: 0.0742 - val_accuracy: 0.8124 - val_loss: 0.8848\n",
            "Epoch 26/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 228ms/step - accuracy: 0.9787 - loss: 0.0667 - val_accuracy: 0.8029 - val_loss: 1.0128\n",
            "Epoch 27/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 224ms/step - accuracy: 0.9783 - loss: 0.0648 - val_accuracy: 0.7934 - val_loss: 0.8854\n",
            "Epoch 28/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 224ms/step - accuracy: 0.9763 - loss: 0.0715 - val_accuracy: 0.8012 - val_loss: 0.9842\n",
            "Epoch 29/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 229ms/step - accuracy: 0.9775 - loss: 0.0693 - val_accuracy: 0.7972 - val_loss: 0.9696\n",
            "Epoch 30/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 228ms/step - accuracy: 0.9791 - loss: 0.0664 - val_accuracy: 0.7868 - val_loss: 0.9319\n",
            "Epoch 31/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 231ms/step - accuracy: 0.9780 - loss: 0.0694 - val_accuracy: 0.8064 - val_loss: 1.0421\n",
            "Epoch 32/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 232ms/step - accuracy: 0.9820 - loss: 0.0569 - val_accuracy: 0.8072 - val_loss: 1.1137\n",
            "Epoch 33/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 235ms/step - accuracy: 0.9806 - loss: 0.0578 - val_accuracy: 0.8085 - val_loss: 0.9897\n",
            "Epoch 34/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m358s\u001b[0m 229ms/step - accuracy: 0.9831 - loss: 0.0537 - val_accuracy: 0.8072 - val_loss: 1.0583\n",
            "Epoch 35/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m365s\u001b[0m 233ms/step - accuracy: 0.9809 - loss: 0.0585 - val_accuracy: 0.8032 - val_loss: 1.0307\n",
            "Epoch 36/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 228ms/step - accuracy: 0.9817 - loss: 0.0539 - val_accuracy: 0.8063 - val_loss: 1.0450\n",
            "Epoch 37/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 235ms/step - accuracy: 0.9837 - loss: 0.0541 - val_accuracy: 0.8065 - val_loss: 0.9981\n",
            "Epoch 38/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m376s\u001b[0m 231ms/step - accuracy: 0.9848 - loss: 0.0460 - val_accuracy: 0.8091 - val_loss: 1.0261\n",
            "Epoch 39/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 230ms/step - accuracy: 0.9841 - loss: 0.0470 - val_accuracy: 0.7981 - val_loss: 1.0842\n",
            "Epoch 40/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m381s\u001b[0m 230ms/step - accuracy: 0.9854 - loss: 0.0477 - val_accuracy: 0.8004 - val_loss: 1.0143\n",
            "Epoch 41/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m385s\u001b[0m 231ms/step - accuracy: 0.9837 - loss: 0.0518 - val_accuracy: 0.8161 - val_loss: 1.0707\n",
            "Epoch 42/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 232ms/step - accuracy: 0.9844 - loss: 0.0489 - val_accuracy: 0.8053 - val_loss: 1.0636\n",
            "Epoch 43/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 229ms/step - accuracy: 0.9851 - loss: 0.0467 - val_accuracy: 0.8010 - val_loss: 1.3022\n",
            "Epoch 44/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 233ms/step - accuracy: 0.9842 - loss: 0.0501 - val_accuracy: 0.8004 - val_loss: 1.1581\n",
            "Epoch 45/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m356s\u001b[0m 228ms/step - accuracy: 0.9848 - loss: 0.0463 - val_accuracy: 0.8050 - val_loss: 1.0455\n",
            "Epoch 46/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 232ms/step - accuracy: 0.9846 - loss: 0.0490 - val_accuracy: 0.7926 - val_loss: 1.2487\n",
            "Epoch 47/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m355s\u001b[0m 227ms/step - accuracy: 0.9852 - loss: 0.0451 - val_accuracy: 0.8080 - val_loss: 1.1095\n",
            "Epoch 48/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 232ms/step - accuracy: 0.9871 - loss: 0.0385 - val_accuracy: 0.8106 - val_loss: 1.0525\n",
            "Epoch 49/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m374s\u001b[0m 228ms/step - accuracy: 0.9865 - loss: 0.0401 - val_accuracy: 0.8095 - val_loss: 1.1521\n",
            "Epoch 50/50\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 230ms/step - accuracy: 0.9865 - loss: 0.0402 - val_accuracy: 0.8082 - val_loss: 1.1518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a4851d56790>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If The Model is Trained with much Datasets, The Accuracy Also Increses"
      ],
      "metadata": {
        "id": "aL6WzJdRQsKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {acc[1]*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biwmVnxyKJUs",
        "outputId": "b898cc2d-42ee-40eb-c451-57f2e3c70210"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 49ms/step - accuracy: 0.8072 - loss: 1.1740\n",
            "Test accuracy: 80.82%\n"
          ]
        }
      ]
    }
  ]
}